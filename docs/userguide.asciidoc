= RobustIRC User Guide =
:numbered:
:toc: right
:stem: latexmath

== Motivation ==

== High-level Overview ==

[[failure_modes]]
=== Failure Modes ===

This chapter describes how RobustIRC behaves when faced with various failure
scenarios. We assume that each RobustIRC node is running on a different
machine, ideally on a different physical machine, as otherwise a failure of the
host machine will lead to not only a single-node failure, but a multiple-node
failure.

The number of nodes necessary to establish quorum depends on the number of
nodes in the network. As an example, in a 3-node network, you need floor(n/2)+1
= 2 nodes to reach quorum. In a 5-node network, you need floor(n/2)+1 = 3 nodes
to reach quorum.

==== Node Failures ====

Node failure means the node does not reply to heartbeats anymore. This could
happen for example because the server process gets killed, because the machine
is powered off, because the machine drops off the network, or many other
reasons.

In case the node was a *follower*, clients which were receiving messages from
that node (GetMessages request) need to connect to a different node before they
can receive any new messages. How long the clients need to realize that the
node has failed depends on the specific failure mode. In the worst case, clients
will timeout a connection after not receiving any data for 1 minute.

In case the node was the *leader*, the previous paragraph also applies.
Additionally, clients will not be able to send new messages until a new leader
is elected. Depending on the network configuration, this typically takes
between 5 and 10 seconds, provided that there are enough nodes that a quorum
can be established. If there are not, the network will remain frozen/read-only
until enough nodes are available.

==== Network Partition ====

Network partition means that some link becomes unavailable, for example because
a physical cable is removed, and the network is partitioned into multiple
parts.

In case the link between the client and any given server within the network
becomes unavailable, the client will just switch to a different server
transparently. Direct contact to the current leader is not required, since
followers will proxy requests for the client when necessary.

In case the link between servers becomes unavailable, the previous section
(„Node Failures“) applies for the server which now became unavailable. In case
the RobustIRC network is structured in such a way that a single link
unavailability affects multiple servers, the problem may be more severe: if the
servers within each network partition cannot reach quorum, the network is
frozen. As an example, in a network with 2 nodes each in 2 datacenters, the
network must freeze when the connection between data centers becomes
unavailable. However, if you had 5 nodes, you would need at least two such link
failures at the same time to be unable to reach quorum.

== Network Performance ==

When talking about RobustIRC performance, these are the dimensions of interest:

messages/s:: This means messages per second for the entire IRC network, where
message is an IRC protocol message, i.e. including nickname changes (not just
`PRIVMSG`).

sessions:: The number of sessions. Each user who uses the bridge to connect to
your RobustIRC network is one session. In traditional IRC networks, one session
would be one TCP connection.

channels:: The number of channels is unlikely to be a scalability problem.
However, the number of sessions participating in a channel, plus the messages/s
within that channel, are an interesting dimension. Each message to a channel
needs to be handed out to every participant in that channel. Therefore,
performance goes down the more messages go into a channel, and it goes down
faster the more sessions participate in each channel.

=== Ballpark numbers ===

If the IRC network you’re running is small, chances are you don’t have a good
idea of how many messages/second your network is handling. There are a couple
of ways to get estimates:

http://search.mibbit.com/networks[mibbit] has a list of networks, and you can
also see their non-secret channels. Looking at the channels of the biggest
networks, there are typically about 300 users in each channel. Of course, there
are outlier channels with 3000+ users, which typically host warez or offer some
other kind of automated content.

https://freenode.net/hosting_ircd.shtml[freenode] cites 320 GiB/month as an
estimate for the traffic required to run a server in the freenode network. If
you assume an average message size of 100 bytes (the maximum being 512 bytes),
this translates to roughly stem:[\frac{320 * 1024^3}{30 * 24 * 60 * 60} / 100 =
1325] messages/s.

http://irc.netsplit.de/networks/top100.php[netsplit.de] has a list of the
biggest networks (excluding some that don’t want to be counted, like freenode).
The number of users for the top 10 range from 10,000 to 50,000 users.

=== Latency ===

TODO(secure): add latency measurements and explanation

== Clients ==

=== Bridge ===

The RobustIRC bridge is a program which bridges between the RobustIRC protocol and standard IRC footnote:[As defined per RFC2812.].

Depending on where the bridge runs, you get two benefits:

1. You can connect to a RobustIRC network with your IRC client of choice.
   Typically, RobustIRC networks will provide a bridge. The recommended
   hostname is `legacy-irc.<networkname>`, e.g. `legacy-irc.robustirc.net`.

2. If the connection between the bridge and your IRC client is stable,
   single-server unavailability and network partitions will be handled
   transparently by the bridge. See <<failure_modes>> for details on the
   failure modes. To get a stable connection to your bridge, you typically need
   to run the bridge on the same machine as your IRC client.

==== SOCKS5 ====

When running a bridge on the same machine as your IRC client, you’d run it
using `robustirc-bridge -socks=localhost:1080` and then configure
`localhost:1080` as the SOCKS5 proxy address to use for connecting to a network
in your IRC client.

.WeeChat: configuring the RobustIRC bridge as a SOCKS proxy
--------------------------------------------------------------------------------
/proxy add bridge socks5 localhost 1080
--------------------------------------------------------------------------------

.WeeChat: connecting to robustirc.net using the SOCKS proxy
--------------------------------------------------------------------------------
/server add robustirc robustirc.net
/set irc.server.robustirc.proxy bridge
/connect robustirc
--------------------------------------------------------------------------------

==== IRC proxy ====

In case your IRC client does either not support SOCKS5 at all or does not
support per-network proxy configuration (e.g. irssi), you can use the bridge in
IRC proxy mode. The downside is that you need to run one bridge instance per
RobustIRC network you want to connect to.

After starting the bridge with `robustirc-bridge -network=<network>`, you can
configure `localhost:6667` as IRC server in your client.

.Starting the bridge in IRC proxy mode
--------------------------------------------------------------------------------
robustirc-bridge -network=robustirc.net
--------------------------------------------------------------------------------

.irssi: Connecting to the configured network
--------------------------------------------------------------------------------
/network add robustirc
/server add -auto -network robustirc localhost 6667
/connect robustirc
--------------------------------------------------------------------------------

== Server Deployment ==

=== Number and Location ===

TODO(secure): explain network sizes and trade-offs, explain how location of servers influences reliability

=== Docker ===

You can use the official
https://registry.hub.docker.com/u/robustirc/robustirc/[docker container
“robustirc/robustirc”] that we provide.

We run one of our servers on CoreOS, which provides quite a restricted
environment, so we describe that setup in the hope that you can easily adapt
it.

In the example systemd service file below, `/media/persistent` is the path on
which we have mounted our persistent storage. We use it to load the TLS
key/certificate from and store the RobustIRC state.

Furthermore, the node runs on the public port `60667`, which reminds of the
conventional `6667` IRC port, but is in the dynamic range. Via `-peer_addr`,
the node’s public address is provided to RobustIRC. This is necessary as docker
uses a private network within the container.

.systemd service file for starting RobustIRC in Docker
--------------------------------------------------------------------------------
[Unit]
Description=RobustIRC
After=docker.service
Requires=docker.service

[Service]
# So that the robustirc-updater can trigger /quit to restart the node.
Restart=always
StartLimitInterval=0

# Always pull the latest version (bleeding edge).
ExecStartPre=/usr/bin/docker pull robustirc/robustirc:latest

ExecStart=/usr/bin/docker run \
  -v /media/persistent:/media/persistent:ro \
  -v /media/persistent/robustirc:/var/lib/robustirc \
  -p :60667:8443 \
  robustirc/robustirc:latest \
    -tls_cert_path=/media/persistent/ssl/combined.crt \
    -tls_key_path=/media/persistent/ssl/robustirc.net.startssl.key \
    -network_password=<secret> \
    -network_name=robustirc.net \
    -peer_addr=dock0.robustirc.net:60667

[Install]
WantedBy=multi-user.target
--------------------------------------------------------------------------------

== Raft Configuration ==

=== Timeouts ===

Timeouts must fulfill this relation:

5ms < LeaderLeaseTimeout <= HeartbeatTimeout <= ElectionTimeout

default: 500ms (LeaderLeaseTimeout) <= 1000ms (HeartbeatTimeout) <= 1000ms (ElectionTimeout)

LeaderLeaseTimeout:: a leader steps down (i.e. does not consider itself the
leader anymore) after it was unable to contact a quorum of nodes for
LeaderLeaseTimeout.

HeartbeatTimeout:: followers enter the candidiate state once they have not
heard from a leader within HeartbeatTimeout. The leader delays for a random
value within [HeartbeatTimeout/10, HeartbeatTimeout/10 * 2] between each ping
to its followers. Therefore, at least 5 (but possibly up to 10) heartbeats must
be missed before HeartbeatTimeout is reached.

ElectionTimeout:: candidates restart the voting process after ElectionTimeout.

CommitTimeout:: See https://github.com/hashicorp/raft/issues/28[hashicorp/raft
issue #28] for details. TODO(secure): run some experiments to see what happens
when this is very low/very high. it’s 50ms by default

As a rule of thumb, figure out the latency of the slowest network link between
your nodes, e.g. by using `ping(8)`. Then, set `HeartbeatTimeout` to 10 times
that latency so that brief network latency spikes are not a problem. Set all
the other timeouts to the same value.

=== MaxAppendEntries ===

TODO(secure): run some experiments to see if we should recommend tuning this value

=== SnapshotThreshold ===

TODO(secure): document

=== TrailingLogs ===

TrailingLogs is the number of raft log entries which are kept after taking a
snapshot. If you have enough log entries to cover a brief node failure (e.g. a
flaky network), raft does not need to send an entire snapshot over the network,
so recovery of the failed node may be quicker.

In case you configure this parameter too low, recovery after a node failure may
consume more bandwidth and may take longer.

In case you configure this parameter too high, the disk usage of RobustIRC will
be higher, as log compactions will occur less frequently.

As a rule of thumb: look at your network’s messages/second, multiply that by
the time of a typical outage, e.g. 5 minutes.
